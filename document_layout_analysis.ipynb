{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aspirina765/Document-Layout-Analysis/blob/master/document_layout_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjBypmTf3ghi"
      },
      "source": [
        "## **Document Layout Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0zEoYZexv38"
      },
      "source": [
        "#### **Package installation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "abXwDycZxv38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf7b6bf-3e41-448d-b1af-b4b851427575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.52-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.52-py3-none-any.whl (901 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m901.7/901.7 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.52 ultralytics-thop-2.0.13\n"
          ]
        }
      ],
      "source": [
        "%pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MYQ2CZtWxv38"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import os # for handling the directory\n",
        "from google.colab import drive # to access the drive\n",
        "import shutil\n",
        "import json\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-lPuSvwxv39"
      },
      "source": [
        "#### **YOLOv8 source**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UW6zoj5nxv39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27186148-0db0-451a-a5ae-7908cad16605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ultralytics'...\n",
            "remote: Enumerating objects: 45810, done.\u001b[K\n",
            "remote: Counting objects: 100% (704/704), done.\u001b[K\n",
            "remote: Compressing objects: 100% (408/408), done.\u001b[K\n",
            "remote: Total 45810 (delta 574), reused 301 (delta 296), pack-reused 45106 (from 3)\u001b[K\n",
            "Receiving objects: 100% (45810/45810), 39.05 MiB | 9.83 MiB/s, done.\n",
            "Resolving deltas: 100% (33935/33935), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download pretrained YOLOv8 model"
      ],
      "metadata": {
        "id": "NWkk_Elw6MHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P ultralytics/ultralytics/yolo https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp8rgg2S5THl",
        "outputId": "df6690bf-24bb-4e74-8c0a-d627e7b1f8fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-21 18:58:21--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/732c503e-9fcb-4a82-be7f-106baafbda15?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241221%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241221T185821Z&X-Amz-Expires=300&X-Amz-Signature=d8c489d0c9afc84f93a183e4c6fb3568ce1344091c354da0f1b7e761157d55ba&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov8n.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-12-21 18:58:21--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/732c503e-9fcb-4a82-be7f-106baafbda15?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241221%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241221T185821Z&X-Amz-Expires=300&X-Amz-Signature=d8c489d0c9afc84f93a183e4c6fb3568ce1344091c354da0f1b7e761157d55ba&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov8n.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6534387 (6.2M) [application/octet-stream]\n",
            "Saving to: â€˜ultralytics/ultralytics/yolo/yolov8n.ptâ€™\n",
            "\n",
            "yolov8n.pt          100%[===================>]   6.23M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2024-12-21 18:58:22 (75.6 MB/s) - â€˜ultralytics/ultralytics/yolo/yolov8n.ptâ€™ saved [6534387/6534387]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLIL5PV9xv39"
      },
      "source": [
        "#### **Train custom dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSiO8fNExv39"
      },
      "source": [
        "**Note: Nake sure to have the \"DLA project\" folder saved as a shortcut under \"MyDrive\"**\n",
        "\n",
        "Get path to labels and images folder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "# Pointing the directory to the shared project folder\n",
        "os.chdir('/content/drive/MyDrive/DLA_project/')\n",
        "cwd = os.getcwd() # cwd = current working directory**"
      ],
      "metadata": {
        "id": "PpqPeVe9zbPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "330715b8-a317-4f97-9e5e-889827516fba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X GET \\\n",
        "     \"https://datasets-server.huggingface.co/first-rows?dataset=ds4sd%2FDocLayNet&config=2022.08&split=train\" \\\n",
        "     -o train.json\n"
      ],
      "metadata": {
        "id": "x9gmQxtSq6hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "https://codait-cos-dax.s3.us.cloud-object-storage.appdomain.cloud/dax-doclaynet/1.0.0/DocLayNet_core.zip"
      ],
      "metadata": {
        "id": "0Y4lmRbfrYsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NVRHL93ra-c",
        "outputId": "19c0781a-f1f1-4746-e0c9-1428f4b86e3c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/480.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/179.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/134.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/194.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import os\n",
        "\n",
        "# Baixar o dataset\n",
        "dataset = load_dataset(\"ds4sd/DocLayNet\", streaming=True)\n",
        "\n",
        "# Definir diretÃ³rio base para salvar o dataset no formato esperado\n",
        "base_dir = '/content/drive/MyDrive/DLA_project/datasets/doclaynet_base'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Criar diretÃ³rios necessÃ¡rios\n",
        "for split in ['train', 'val', 'test']:\n",
        "    os.makedirs(os.path.join(base_dir, f'{split}/images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(base_dir, f'{split}/annotations'), exist_ok=True)\n"
      ],
      "metadata": {
        "id": "VcwmIFGlslvs"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import json\n",
        "\n",
        "def save_split(dataset_split, split_name):\n",
        "    image_dir = os.path.join(base_dir, f'{split_name}/images')\n",
        "    annotation_dir = os.path.join(base_dir, f'{split_name}/annotations')\n",
        "\n",
        "    for row in dataset_split:\n",
        "        # Salvar a imagem\n",
        "        image_path = os.path.join(image_dir, f\"{row['image_id']}.jpg\")\n",
        "        image = row['image']\n",
        "        image.save(image_path)\n",
        "\n",
        "        # Salvar as anotaÃ§Ãµes no formato YOLO\n",
        "        annotation_path = os.path.join(annotation_dir, f\"{row['image_id']}.txt\")\n",
        "        with open(annotation_path, 'w') as f:\n",
        "            for obj in row['objects']:\n",
        "                class_id = obj['category_id']  # Ajustar conforme o mapeamento de classes\n",
        "                bbox = obj['bbox']  # [x_min, y_min, width, height]\n",
        "                x_center = bbox[0] + bbox[2] / 2\n",
        "                y_center = bbox[1] + bbox[3] / 2\n",
        "                width = bbox[2]\n",
        "                height = bbox[3]\n",
        "\n",
        "                # Normalizar para valores entre 0 e 1\n",
        "                x_center /= row['width']\n",
        "                y_center /= row['height']\n",
        "                width /= row['width']\n",
        "                height /= row['height']\n",
        "\n",
        "                # Escrever no formato YOLO: class_id x_center y_center width height\n",
        "                f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
        "\n",
        "# Salvar os splits (train, val, test)\n",
        "save_split(dataset['train'], 'train')\n",
        "save_split(dataset['validation'], 'val')\n",
        "save_split(dataset['test'], 'test')\n"
      ],
      "metadata": {
        "id": "MMGWNHG3rPu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_content = \"\"\"\n",
        "path: /content/drive/MyDrive/DLA_project/datasets/doclaynet_base/\n",
        "train: train/images\n",
        "val: val/images\n",
        "test: test/images\n",
        "names:\n",
        "  0: Caption\n",
        "  1: Footnote\n",
        "  2: Formula\n",
        "  3: List-item\n",
        "  4: Page-footer\n",
        "  5: Page-header\n",
        "  6: Picture\n",
        "  7: Section-header\n",
        "  8: Table\n",
        "  9: Text\n",
        "  10: Title\n",
        "\"\"\"\n",
        "with open('/content/drive/MyDrive/DLA_project/datasets/doclaynet_base/doclaynet.yaml', 'w') as f:\n",
        "    f.write(yaml_content)\n"
      ],
      "metadata": {
        "id": "G58V4KTfr9_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Dnupls9r-fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "m63WcFblxv39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "23915ab3-649e-468e-be2b-78d38628a924"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n@article{doclaynet2022,\\n  title = {DocLayNet: A Large Human-Annotated Dataset for Document-Layout Segmentation},\\n  doi = {10.1145/3534678.353904},\\n  url = {https://doi.org/10.1145/3534678.3539043},\\n  author = {Pfitzmann, Birgit and Auer, Christoph and Dolfi, Michele and Nassar, Ahmed S and Staar, Peter W J},\\n  year = {2022},\\n  isbn = {9781450393850},\\n  publisher = {Association for Computing Machinery},\\n  address = {New York, NY, USA},\\n  booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},\\n  pages = {3743â€“3751},\\n  numpages = {9},\\n  location = {Washington DC, USA},\\n  series = {KDD '22}\\n}\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "dataset_folder = os.path.join(cwd, 'datasets/doclaynet_base') # Base dataset: 6910 train, 648 val, 499 test\n",
        "\"\"\"\n",
        "@article{doclaynet2022,\n",
        "  title = {DocLayNet: A Large Human-Annotated Dataset for Document-Layout Segmentation},\n",
        "  doi = {10.1145/3534678.353904},\n",
        "  url = {https://doi.org/10.1145/3534678.3539043},\n",
        "  author = {Pfitzmann, Birgit and Auer, Christoph and Dolfi, Michele and Nassar, Ahmed S and Staar, Peter W J},\n",
        "  year = {2022},\n",
        "  isbn = {9781450393850},\n",
        "  publisher = {Association for Computing Machinery},\n",
        "  address = {New York, NY, USA},\n",
        "  booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},\n",
        "  pages = {3743â€“3751},\n",
        "  numpages = {9},\n",
        "  location = {Washington DC, USA},\n",
        "  series = {KDD '22}\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfpJDPLUxv39"
      },
      "source": [
        "Generate labels folders containing txt files in YOLO format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LNk_X3E_xv39"
      },
      "outputs": [],
      "source": [
        "def create_folder(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9Oj-rH1Uxv39"
      },
      "outputs": [],
      "source": [
        "create_folder(os.path.join(dataset_folder, 'train', 'labels'))\n",
        "create_folder(os.path.join(dataset_folder, 'test', 'labels'))\n",
        "create_folder(os.path.join(dataset_folder, 'val', 'labels'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48tN9hbexv3-"
      },
      "source": [
        "Parse json files and convert them into txt files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9ZhwmgI0xv3-"
      },
      "outputs": [],
      "source": [
        "# Define the classes\n",
        "classes = ['Caption', 'Footnote', 'Formula', 'List-item', 'Page-footer', 'Page-header', 'Picture', 'Section-header', 'Table', 'Text', 'Title']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9f6GL0Qtxv3-"
      },
      "outputs": [],
      "source": [
        "# Take in a json file for each image, convert it into txt file\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "def convert_coco_json_to_txt(json_dir, output_dir):\n",
        "    # Import json\n",
        "    with open(json_dir) as f:\n",
        "        fn = Path(output_dir) # folder name\n",
        "        data = json.load(f)\n",
        "\n",
        "        # Write labels file\n",
        "        h, w, f = data['metadata']['coco_height'], data['metadata']['coco_height'], data['metadata']['page_hash']\n",
        "\n",
        "        bboxes = []\n",
        "        for obj in data['form']:\n",
        "            # The COCO box format is [top left x, top left y, width, height]\n",
        "            box = np.array(obj['box'], dtype=np.float64)\n",
        "            box[:2] += box[2:] / 2  # xy top-left corner to center\n",
        "            box[[0, 2]] /= w  # normalize x\n",
        "            box[[1, 3]] /= h  # normalize y\n",
        "            if box[2] <= 0 or box[3] <= 0:  # if w <= 0 and h <= 0\n",
        "                continue\n",
        "\n",
        "            cls = classes.index(obj['category'])  # class\n",
        "            box = [cls] + box.tolist()\n",
        "            if box not in bboxes:\n",
        "                bboxes.append(box)\n",
        "\n",
        "        # Write\n",
        "        with open((fn / f).with_suffix('.txt'), 'a') as file:\n",
        "            for i in range(len(bboxes)):\n",
        "                line = *(bboxes[i]),  # cls, box or segments\n",
        "                file.write(('%g ' * len(line)).rstrip() % line + '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define folder directories for train/val/test\n",
        "train_folder = os.path.join(dataset_folder, \"train\")\n",
        "val_folder = os.path.join(dataset_folder, \"val\")\n",
        "test_folder = os.path.join(dataset_folder, \"test\")\n",
        "folders = [train_folder, val_folder, test_folder]"
      ],
      "metadata": {
        "id": "-1Lw-MHe8d92"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cRJYDEltxv3-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "64dd4944-3744-46ac-864a-597722afb4c0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "StopIteration",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-2943510bd044>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generate txt files from json files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'annotations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mconvert_coco_json_to_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'annotations'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Generate txt files from json files\n",
        "for folder in folders:\n",
        "    _, _, json_file = next(os.walk(os.path.join(folder, 'annotations')))\n",
        "    for f in json_file:\n",
        "        convert_coco_json_to_txt(os.path.join(folder, 'annotations', f), os.path.join(folder, 'labels'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Create yaml file to store dataset's information**"
      ],
      "metadata": {
        "id": "qiIlLeHV_m3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Create a folder in current working directory (in Drive)"
      ],
      "metadata": {
        "id": "1f0oyO_G03Oz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "create_folder(os.path.join(cwd, \"ultralytics/ultralytics/datasets\"))"
      ],
      "metadata": {
        "id": "Fiv3c-PWCUHl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Create a yaml file named doclaynet.yaml\n",
        "3. Paste the content as follows:"
      ],
      "metadata": {
        "id": "Mo3Nimko_s2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "path: doclaynet_base/  # dataset root dir\n",
        "train: train/images  # train images\n",
        "val: val/images  # val images\n",
        "test: test/images\n",
        "\n",
        "# Classes\n",
        "names:\n",
        "  0: Caption\n",
        "  1: Footnote\n",
        "  2: Formula\n",
        "  3: List-item\n",
        "  4: Page-footer\n",
        "  5: Page-header\n",
        "  6: Picture\n",
        "  7: Section-header\n",
        "  8: Table\n",
        "  9: Text\n",
        "  10: Title\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "NBIjSO-DABZG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "26ed6bcc-7c4e-4fb9-c3b5-ca663cec50c3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\npath: doclaynet_base/  # dataset root dir\\ntrain: train/images  # train images\\nval: val/images  # val images\\ntest: test/images\\n\\n# Classes\\nnames:\\n  0: Caption\\n  1: Footnote\\n  2: Formula\\n  3: List-item\\n  4: Page-footer\\n  5: Page-header\\n  6: Picture\\n  7: Section-header\\n  8: Table\\n  9: Text\\n  10: Title\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqQYfXf1xv3-"
      },
      "source": [
        "#### **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "k5I5p27Cxv3-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f267891c-2c2b-4946-a030-8e40ef82d9c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.52 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=ultralytics/ultralytics/yolo/yolov8n.pt, data=ultralytics/ultralytics/datasets/doclaynet.yaml, epochs=10, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=1, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 562, in get_dataset\n",
            "    data = check_det_dataset(self.args.data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/utils.py\", line 329, in check_det_dataset\n",
            "    raise FileNotFoundError(m)\n",
            "FileNotFoundError: \n",
            "Dataset 'ultralytics/ultralytics/datasets/doclaynet.yaml' images not found âš ï¸, missing path '/content/drive/MyDrive/DLA_project/datasets/doclaynet_base/val/images'\n",
            "Note dataset download directory is '/content/drive/MyDrive/DLA_project/datasets'. You can update this in '/root/.config/Ultralytics/settings.json'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 972, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 800, in train\n",
            "    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 133, in __init__\n",
            "    self.trainset, self.testset = self.get_dataset()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 566, in get_dataset\n",
            "    raise RuntimeError(emojis(f\"Dataset '{clean_url(self.args.data)}' error âŒ {e}\")) from e\n",
            "RuntimeError: Dataset 'ultralytics/ultralytics/datasets/doclaynet.yaml' error âŒ \n",
            "Dataset 'ultralytics/ultralytics/datasets/doclaynet.yaml' images not found âš ï¸, missing path '/content/drive/MyDrive/DLA_project/datasets/doclaynet_base/val/images'\n",
            "Note dataset download directory is '/content/drive/MyDrive/DLA_project/datasets'. You can update this in '/root/.config/Ultralytics/settings.json'\n",
            "Sentry is attempting to send 2 pending events\n",
            "Waiting up to 2 seconds\n",
            "Press Ctrl-C to quit\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=train model=ultralytics/ultralytics/yolo/yolov8n.pt data=ultralytics/ultralytics/datasets/doclaynet.yaml epochs=10 imgsz=640 workers=1 batch=32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSpkbrbvxv3-"
      },
      "source": [
        "#### **Inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jWaQF1Fxv3-"
      },
      "outputs": [],
      "source": [
        "!yolo task=detect mode=predict model=runs/detect/train/weights/best.pt conf=0.1 source='test_images/*.jpg'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show an example:"
      ],
      "metadata": {
        "id": "_uz9Eai8WA3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "example = Image.open('runs/detect/predict/PMC1277013_00004.jpg')\n",
        "example.show()"
      ],
      "metadata": {
        "id": "YVzINUGWWCyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UaaF00jxv3-"
      },
      "source": [
        "#### **Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frNmHI9Exv3_"
      },
      "outputs": [],
      "source": [
        "!yolo task=detect mode=val model=runs/detect/train/weights/best.pt name=yolov8_eval data=ultralytics/ultralytics/datasets/doclaynet.yaml imgsz=640"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac_sH-tKxv3_"
      },
      "source": [
        "##### **Evaluation Metrics Breakdown**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All metrics"
      ],
      "metadata": {
        "id": "gcKbW_nMzu6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "results = Image.open('runs/detect/train/results.png')\n",
        "results.show()"
      ],
      "metadata": {
        "id": "RxV_3OSmzwNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read more from [this link](https://stackoverflow.com/questions/54977311/what-is-loss-cls-and-loss-bbox-and-why-are-they-always-zero-in-training#:~:text=loss_cls%20%3A%20a%20loss%20that%20measures,usually%20called%20cross%20entropy%20loss)\n",
        "\n",
        "> Box loss: measures how tight the predicting bounding boxes are to the ground truth boxes.\n",
        "\n",
        "> Class loss: measures the accuracy of the model's classification of whether a predicted box contains an object or \"background\"\n",
        "\n",
        "- Class loss is relatively high on the train dataset, but the model seems to generalize well on unseen data, evidenced by val class loss.\n",
        "- Box loss converges, but still, the final value is still high"
      ],
      "metadata": {
        "id": "IBdaJ7zn2Vmm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSYPopRdxv3_"
      },
      "source": [
        "Considering the precision-recall curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzKy2SJpxv3_"
      },
      "outputs": [],
      "source": [
        "precision_recall_curve = Image.open('runs/detect/yolov8_eval/PR_curve.png')\n",
        "precision_recall_curve.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meQW6UvDxv3_"
      },
      "source": [
        "Considering mAP metrics:\n",
        "- Not a good model, since a good model should have high precision and recall when confidence threshold varies (a good model's curve should move closer to the top-right corner)\n",
        "- Better at detecting Page-footers, Page-headers, Tables, Text, Caption\n",
        "- Need improvement: Title, Footnote (may be a scale issue-could resolve by increasing the training size)\n",
        "- However, for the general task at hand, we might prioritize recall over precision.\n",
        "In such case, we might improve the model by increasing image's size when training (but would also need to consider processing time as a trade-off)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Next step**"
      ],
      "metadata": {
        "id": "MWtjP5pF1r7P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Consider training a larger dataset so that each class has comparable exposure to the learning model\n",
        "\n",
        "> \"Images per class. â‰¥1.5k images per class\"\n",
        "\n",
        "> \"Instances per class. â‰¥10k instances (labeled objects) per class total\"\n",
        "\n",
        "- Consider adding background images to dataset to reduce false positives\n",
        "\n",
        "> \"Background images. Background images are images with no objects that are added to a dataset to reduce False Positives (FP). We recommend about 0-10% background images to help reduce FPs (COCO has 1000 background images for reference, 1% of the total).\"\n",
        "\n",
        "- Take into account devices this application will be used on the select the most suitable pretrained model\n",
        "\n",
        "> Larger models like YOLOv5x will produce better results in nearly all cases, but have more parameters and are slower to run. For mobile applications we recommend YOLOv5s/m, for cloud or desktop applications we recommend YOLOv5l/x."
      ],
      "metadata": {
        "id": "QeeP5ty71x6Q"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}